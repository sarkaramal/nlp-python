{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constant\n",
    "stop_words = set(stopwords.words('english'))\n",
    "SAMPLE_SIZE = 10000\n",
    "MAX_TOPIC = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking 1000 random of the dataset for test\n",
    "df = pd.read_csv('abcnews-date-text.csv')\n",
    "df = df.sample(n = SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for col in df[\"headline_text\"]:\n",
    "    col = re.sub('^[A-Za-z]',\"\",col)\n",
    "    word_tokens = word_tokenize(col)\n",
    "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
    "    stem_tokens = [stemmer.stem(w) for w in filtered_tokens]\n",
    "    lammetized_tokens = [lemmatizer.lemmatize(w) for w in stem_tokens]\n",
    "    corpus.append(lammetized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 heat\n",
      "1 leav\n",
      "2 mum\n",
      "3 penrith\n",
      "4 young\n",
      "5 attack\n",
      "6 boy\n",
      "7 nake\n",
      "8 northern\n",
      "9 nsw\n",
      "10 lectrolux\n",
      "11 shutdown\n",
      "12 coach\n",
      "13 estern\n",
      "14 gombau\n",
      "15 josep\n",
      "16 sack\n",
      "17 sydney\n",
      "18 wander\n",
      "19 detain\n",
      "20 korea\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for k,v in dictionary.iteritems():\n",
    "    print(k,v)\n",
    "    count+=1\n",
    "    if count>20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus=[dictionary.doc2bow(doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    }
   ],
   "source": [
    "lda_model=gensim.models.LdaMulticore(bow_corpus,\n",
    "                                    num_topics=MAX_TOPIC,\n",
    "                                    id2word=dictionary,\n",
    "                                    passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.007*\"plan\" + 0.007*\"help\" + 0.006*\"fire\" + 0.005*\"sw\" + 0.005*\"nterview\" + 0.004*\"hospit\" + 0.004*\"olic\" + 0.004*\"flood\" + 0.004*\"report\" + 0.004*\"case\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.008*\"say\" + 0.006*\"car\" + 0.006*\"kill\" + 0.005*\"delay\" + 0.004*\"power\" + 0.004*\"olic\" + 0.004*\"u\" + 0.004*\"dead\" + 0.004*\"new\" + 0.004*\"sex\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.008*\"win\" + 0.005*\"say\" + 0.005*\"plan\" + 0.004*\"chang\" + 0.004*\"coast\" + 0.003*\"titl\" + 0.003*\"name\" + 0.003*\"home\" + 0.003*\"boost\" + 0.003*\"water\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.011*\"charg\" + 0.009*\"polic\" + 0.008*\"man\" + 0.007*\"attack\" + 0.006*\"call\" + 0.005*\"murder\" + 0.005*\"court\" + 0.005*\"olic\" + 0.005*\"back\" + 0.004*\"kill\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.006*\"say\" + 0.005*\"fire\" + 0.004*\"plan\" + 0.004*\"claim\" + 0.004*\"pm\" + 0.003*\"nsw\" + 0.003*\"cut\" + 0.003*\"vote\" + 0.003*\"health\" + 0.003*\"hous\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.005*\"court\" + 0.005*\"win\" + 0.004*\"rate\" + 0.004*\"new\" + 0.004*\"charg\" + 0.004*\"open\" + 0.003*\"warn\" + 0.003*\"elect\" + 0.003*\"law\" + 0.003*\"qld\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.006*\"urg\" + 0.005*\"miss\" + 0.005*\"call\" + 0.005*\"chang\" + 0.004*\"head\" + 0.004*\"u\" + 0.004*\"worker\" + 0.003*\"health\" + 0.003*\"say\" + 0.003*\"water\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.005*\"plan\" + 0.004*\"get\" + 0.004*\"crash\" + 0.004*\"say\" + 0.004*\"world\" + 0.004*\"report\" + 0.003*\"prison\" + 0.003*\"drive\" + 0.003*\"fire\" + 0.003*\"home\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.005*\"test\" + 0.004*\"new\" + 0.004*\"australia\" + 0.004*\"year\" + 0.004*\"light\" + 0.003*\"olic\" + 0.003*\"die\" + 0.003*\"jail\" + 0.003*\"one\" + 0.003*\"attack\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.004*\"nation\" + 0.004*\"charg\" + 0.004*\"plan\" + 0.003*\"year\" + 0.003*\"murder\" + 0.003*\"tax\" + 0.003*\"fire\" + 0.003*\"final\" + 0.003*\"kill\" + 0.003*\"student\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx,topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.010007298),\n",
       " (1, 0.010007434),\n",
       " (2, 0.010007923),\n",
       " (3, 0.01000806),\n",
       " (4, 0.010007644),\n",
       " (5, 0.9099319),\n",
       " (6, 0.010007212),\n",
       " (7, 0.010007176),\n",
       " (8, 0.010007675),\n",
       " (9, 0.010007671)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model[bow_corpus[4310]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(402, 1), (713, 1), (1712, 1), (1754, 1)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8198750019073486 \n",
      "topic: 0 \n",
      "[(5, '0.005*\"court\"'), (2, '0.008*\"win\"'), (3, '0.011*\"charg\"'), (4, '0.006*\"say\"'), (7, '0.005*\"plan\"'), (1, '0.008*\"say\"'), (0, '0.007*\"plan\"'), (9, '0.004*\"nation\"'), (8, '0.005*\"test\"'), (6, '0.006*\"urg\"')]\n",
      "\n",
      "Score: 0.02002139575779438 \n",
      "topic: 9 \n",
      "[(2, '0.008*\"win\"'), (5, '0.005*\"court\"'), (6, '0.006*\"urg\"'), (1, '0.008*\"say\"'), (3, '0.011*\"charg\"'), (4, '0.006*\"say\"'), (7, '0.005*\"plan\"'), (9, '0.004*\"nation\"'), (8, '0.005*\"test\"')]\n",
      "\n",
      "Score: 0.020018182694911957 \n",
      "topic: 1 \n",
      "[(8, '0.005*\"test\"')]\n",
      "\n",
      "Score: 0.020013956353068352 \n",
      "topic: 2 \n",
      "[(2, '0.008*\"win\"'), (5, '0.005*\"court\"')]\n",
      "\n",
      "Score: 0.020013757050037384 \n",
      "topic: 7 \n",
      "[(2, '0.008*\"win\"'), (5, '0.005*\"court\"'), (4, '0.006*\"say\"'), (7, '0.005*\"plan\"'), (3, '0.011*\"charg\"'), (9, '0.004*\"nation\"'), (6, '0.006*\"urg\"')]\n",
      "\n",
      "Score: 0.020012732595205307 \n",
      "topic: 6 \n",
      "[(8, '0.005*\"test\"'), (7, '0.005*\"plan\"'), (0, '0.007*\"plan\"'), (4, '0.006*\"say\"'), (2, '0.008*\"win\"'), (9, '0.004*\"nation\"')]\n",
      "\n",
      "Score: 0.02001270279288292 \n",
      "topic: 3 \n",
      "[(6, '0.006*\"urg\"'), (9, '0.004*\"nation\"'), (4, '0.006*\"say\"')]\n",
      "\n",
      "Score: 0.020011408254504204 \n",
      "topic: 4 \n",
      "[(2, '0.008*\"win\"'), (1, '0.008*\"say\"'), (6, '0.006*\"urg\"'), (7, '0.005*\"plan\"')]\n",
      "\n",
      "Score: 0.02001107856631279 \n",
      "topic: 8 \n",
      "[(6, '0.006*\"urg\"'), (1, '0.008*\"say\"'), (5, '0.005*\"court\"'), (3, '0.011*\"charg\"'), (8, '0.005*\"test\"'), (7, '0.005*\"plan\"'), (9, '0.004*\"nation\"'), (4, '0.006*\"say\"')]\n",
      "\n",
      "Score: 0.020009774714708328 \n",
      "topic: 5 \n",
      "[(1, '0.008*\"say\"'), (9, '0.004*\"nation\"'), (0, '0.007*\"plan\"'), (7, '0.005*\"plan\"'), (6, '0.006*\"urg\"')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,score in sorted(lda_model[bow_corpus[6000]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {} \\ntopic: {} \\n{}\\n\".format(score, index, lda_model.print_topics(index, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
